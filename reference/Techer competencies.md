# כשירות מגולמת בעידן ה‑AI: האם מחנכים חייבים לתרגל אישית את “מערכת ההפעלה האנושית” כדי לטפח אותה אצל תלמידים?

## תקציר מנהלים

הדילמה המנחה של הדוח אינה “האם ללמד AI” אלא האם, בסביבה חינוכית רוויה ב‑Generative AI, די בכך שמורים **יבינו** את חמש כשירויות “מערכת ההפעלה האנושית” ויתכננו פעילויות עבור תלמידים (אפשרות A), או שהוראה אפקטיבית ולגיטימית מחייבת שהם **יחיו אותן בפועל**—יתרגלו, ייכשלו, יתקנו, וידגימו בזמן אמת חשיבה שיפוטית ומוסרית בתוך אינטראקציה עם AI (אפשרות B). ההבדל העמוק בין A ל‑B הוא בין “ידע על” הכשירות (ידע הצהרתי/מושגי) לבין “ידע כיצד” ו“נטייה לעשות” (procedural + dispositional)—היכולת לבצע ניטור, בקרה, תיקון ושיפוט תחת אי‑ודאות, לחץ זמן ופיתוי של פתרון קל. citeturn0search0turn1search1turn7search2

### ממצא מרכזי: האותנטיות הפדגוגית בעידן ה‑AI היא בעיקר פדגוגיה של נראות חשיבתית, לא של “העברת תשובות”
במסורות של חניכות קוגניטיבית (cognitive apprenticeship), הלמידה של מיומנויות מורכבות מתרחשת כאשר המומחה **מגלם** ומבצע את הפעולה, ומנכיח לתלמידים תהליכים סמויים—במיוחד: שיקולים, היסוסים, בדיקות, וקבלת החלטות. במודל זה, “להנחות פעילות” בלי להדגים את החשיבה המומחית (או לפחות לאפשר גישה עקבית אליה דרך דוגמאות/פרוטוקולים אמיתיים) מפחית משמעותית את הסיכוי שהתלמידים יפתחו את אותה מיומנות בדיוק. citeturn0search0turn0search4turn0search20

### ממצא מרכזי: בסביבה רוויה ב‑AI, סמכות אפיסטמית כבר אינה “אני יודע”, אלא “אני מווסת איך יודעים”
ספרות עדכנית על “סמכות אפיסטמית” (epistemic authority) בסביבות למידה עם Generative AI מצביעה על כך שמערכות אלה פועלות בפועל כ”יודע חלופי” (surrogate knower), שמייצר טקסטים נראים‑אמינים, לעיתים בביטחון רטורי גם כשהם שגויים. במצב כזה, המורה מאבד באופן מבני חלק מהיתרון של “מקור הידע”, והלגיטימציה עוברת לכיוון המורה כ**מנטור אפיסטמי**: מי שמלמד איך מייצרים הצדקה, איך בודקים, איך מחזיקים אי‑ודאות, ואיך מתעדפים ערכים מול יעילות. citeturn1search1turn1search9

### מה חזק במחקר ומה עדיין מתהווה
* **חזק יחסית (מבוסס מסורת מחקרית רחבה):**  
  1) חשיבות המידול (modeling) והפיכת החשיבה לנראית בחניכות קוגניטיבית. citeturn0search0turn0search4  
  2) יכולת ללמד חשיבה ביקורתית באמצעות הוראה מפורשת (explicit instruction), עם השפעות חיוביות ממוצעות אך שונות רבה בין התערבויות. citeturn0search5turn0search13  
  3) אפקטיביות של התערבויות בלמידה מווסתת‑עצמית (SRL) ומטא‑קוגניציה, כולל תפקיד של “חשיבה בקול” ומודלים. citeturn1search7turn1search15turn4search19  
  4) ההבנה שהעברה (transfer)—במיוחד “עברה רחוקה”—אינה אוטומטית ודורשת רפלקציה מטא‑קוגניטיבית ותכנון שמקרב את התלמיד למופעי ביצוע דומים (“hugging/bridging”). citeturn4search34turn4search18  

* **מתהווה (2023–2026; יותר סקרים/מחקרי שדה מאשר RCTs):**  
  1) ראיות לכך ששימוש תדיר ב‑GenAI קשור לירידה בדיווח‑עצמי או במדדים של “חשיבה ביקורתית”, כש“העברת עומס קוגניטיבי” (cognitive offloading) מתווכת את הקשר—אך רוב מחקרים אלה קורלטיביים ולכן לא מוכיחים סיבתיות. citeturn0search19turn0search3turn1search24  
  2) ראיות שהתערבויות “אינוקולציה”/הכשרה ממוקדת יכולות להגדיל כוונות אימות והתנהגות אימות בפועל במגע עם ChatGPT. citeturn1search4  
  3) תיעוד של מורים/מתכשרים שמסתייעים ב‑ChatGPT לתכנון הוראה ואז מבצעים רפלקציה ביקורתית על הפלט—כלומר, למידה מקצועית דרך שימוש. citeturn3search5turn3search8turn3search12  

### מסקנה נורמטיבית‑אמפירית משולבת
בהינתן (א) מה שידוע על חניכות קוגניטיבית, מידול, מטא‑קוגניציה והעברה; (ב) האופן שבו GenAI משנה סמכות ו“תכנית לימודים סמויה” לגבי נורמות ידע; ו‑(ג) הממצאים המתהווים על offloading ואימות—המסקנה הסבירה ביותר היא:

**כדי לטפח באופן אותנטי ועמיד את חמש כשירויות “מערכת ההפעלה האנושית”, המורה צריך לכל הפחות רמה מהותית של התגלמות‑בפועל (B‑lite): תרגול אישי מתמשך בתוך קונטקסטים של AI, כולל חשיפה לשגיאות/הזיות, דילמות אתיות, וניהול פיתוי של קיצור דרך.** לא תמיד נדרשת “מומחיות על” או שליטה טכנית גבוהה, אך נדרשת **נוכחות חווייתית + יכולת מידול** של בדיקה, שיקוף ושיפוט. citeturn0search0turn1search1turn0search5turn1search7turn1search4  

במילים אחרות: אפשרות A (“להבין ולתכנן”) עשויה להספיק ליצירת פעילויות נקודתיות, אך בסביבה רוויה ב‑AI היא פגיעה לשני כשלים עקביים:  
1) **כשל מנגנוני**: תלמידים לא רואים “איך חושבים” מול פיתוי של תשובה מיידית, ולכן לא בונים פרוטוקולי אימות ושיפוט בזמן אמת. citeturn0search0turn4search19  
2) **כשל לגיטימציה‑סמויה**: התלמידים מסיקים נורמות מהתנהגות המורה (כולל הימנעות, או שימוש לא‑ביקורתי), והפער בין מה שנאמר למה שנעשה פוגע באמון ובאימוץ הכשירות. citeturn2search5turn5search3turn10search12  

### מה זה אומר לגבי חמש הכשירויות (תמצית)
* **ניסוח שאלות/משמעת חקירה:** לא רק ללמד “שאלות טובות”, אלא להדגים כיצד שואלים ומזקקים שאלות מול AI, כיצד חוזרים לאי‑בהירות, וכיצד הופכים שאלה לבדיקת טענות. citeturn4search0turn8search0turn0search0  
* **הערכה ביקורתית של פלט AI:** קשה לבנות “חשדנות אפיסטמית” בלי שמורה עצמו התנסה בהזיות/טעויות משכנעות; אימון אימות ספציפי מראה פוטנציאל אמפירי. citeturn1search4turn4search5turn1search1  
* **שיפוט אתי ושימוש אחראי:** במוסר וביושרה אקדמית, המורה הוא גם דמות‑מודל; מחקרי “חינוך לאופי/מידות” מראים אפקטים חיוביים קטנים‑בינוניים, אך מדגישים חשיבות עקביות, קשר, ותיווך. citeturn5search0turn6search15turn6search6  
* **למידה אדפטיבית תחת אי‑ודאות טכנולוגית:** כאן הליבה היא SRL ומטא‑קוגניציה—והמחקר תומך בהוראה שמדגימה ניטור ובקרה. citeturn1search7turn1search15turn4search19  
* **שמירת האדם מעל המכונה:** זהו שילוב של סוכנות, אחריות, וויסות רגשי ואמון. מטא‑אנליזות על SEL מצביעות על השפעות חיוביות, והספרות על אמון מורה‑תלמיד מציעה שאמון הוא מנוע הישגים; לכן, כשירות זו כמעט בהגדרה תלויה בהתגלמות. citeturn2search3turn5search26turn10search12  

## הבהרת מושגים: “כשירות מגולמת” ומערכת ההפעלה האנושית

“כשירות מגולמת” (embodied competence) בדוח זה פירושה: **היכולת לבצע בפועל** מערך פעולות‑חשיבה (cognitive actions) במצבים אמיתיים—כולל מצבים לא‑נקיים—כך שהביצוע נשען על הרגלים, תשומת לב, רפלקציה, שיפוט ערכי, וניהול רגשות (כגון בלבול, ביטחון‑יתר, או חרדה אפיסטמית). היא אינה זהה להבנה תאורטית של מושגים (“אני יודע מה זה אימות”) אלא כוללת “ידיעה‑במעשה” (knowing‑in‑action) והיכולת לשקף תוך כדי פעולה (reflection‑in‑action). citeturn7search2turn7search5turn0search0  

שלוש מסורות פילוסופיות‑חינוכיות עוזרות לדייק את ההבחנה הזו:

* אצל entity["people","ג'ון דיואי","american philosopher"], “חינוך” נקשר לשחזור מתמשך של ניסיון (reconstruction of experience): איכות הלמידה תלויה באיכות החוויה ובאופן שבו היא מייצרת הרגלים ויכולת הסתגלות, לא רק בהצהרות נכונות. citeturn7search25turn7search10  
* אצל entity["people","פאולו פריירה","brazilian educator"], השאלה של אותנטיות קשורה ל‑praxis: לא די בדיבור על ביקורתיות ודיאלוג; המורה עצמו “נבחן” בשותפות, בדיאלוג, וביחס שאינו מחפיץ את התלמיד כצרכן ידע. בהקשר שלנו, AI יכול להפוך גם תלמיד וגם מורה לצרכני טקסט “מוכן”, ולכן praxis דורשת התמודדות חיה עם פיתוי זה. citeturn7search14turn7search1  
* אצל entity["people","דונלד שנון","reflective practice scholar"], מקצוענות מתוארת כיכולת לפעול בתוך מצבים ייחודיים, לא‑ודאיים ומלאי קונפליקט—באמצעות רפלקציה‑בפעולה. סביבת GenAI מגדילה בדיוק סוג כזה של אי‑ודאות (האם הפלט אמין? האם ההשוואה הוגנת? מה “נחשב” עבודה מקורית?). לכן הספירה האפיסטמית החדשה הופכת את “המתרגל הרפלקטיבי” ממטאפורה לדרישת יסוד. citeturn7search2turn7search27  

### חמש הכשירויות כ”מערכת הפעלה” בסביבה רוויית AI
המסגרת שהוגדרה בשאלה (“מערכת ההפעלה האנושית”) ניתנת לקריאה כמערכת מתואמת של רכיבים שמאפשרים ללומד להישאר סוכן (agent) ולא להפוך ל”צינור” של טקסט:  
1) **משמעת חקירה/ניסוח שאלות** – מה לשאול, למה זה חשוב, ואיך הופכים שאלה לתהליך בדיקה. citeturn4search0turn8search0  
2) **הערכה ביקורתית של פלט AI** – חשדנות מושכלת, אימות והצלבה, וכישורי הערכת מקורות בסביבה דיגיטלית. citeturn4search5turn1search4  
3) **שיפוט אתי ושימוש אחראי** – יושרה, בעלות אינטלקטואלית, אחריות להטיות/השלכות, ושיקולים של הוגנות ושקיפות. citeturn6search15turn6search6turn6search13  
4) **למידה אדפטיבית תחת אי‑ודאות** – SRL, מטא‑למידה, ענווה אפיסטמית, ונכונות לעדכן פרקטיקות. citeturn1search7turn1search15turn7search2  
5) **השארת האדם מעל המכונה** – שיפוט אנושי סופי, יצירתיות ואחריות מוסרית, בנוסף למרכיבי יחסים ואמון שמנועי‑הלמידה תלויים בהם. citeturn2search3turn10search12turn5search0  

בנקודת החיבור הזו, “כשירות מגולמת” פירושה שמורה שמבקש לטפח את המערכת חייב להפעיל אותה בעצמו בהקשרים מקבילים—לפחות במידה שמאפשרת לו **להנכיח** תהליכים סמויים, **להחזיק** נורמות, ו**לגלם** אחריות. citeturn0search0turn1search1  

## עדויות על מידול מול הנחיה בלבד

### חניכות קוגניטיבית: “להפוך חשיבה לנראית” כמנגנון הוראה ליבה
המודל הקלאסי של חניכות קוגניטיבית מתאר למידה של מיומנויות מורכבות כשרשרת שיטתית של: modeling (הדגמה), coaching (אימון), scaffolding & fading (תמיכה ונסיגה), articulation (ניסוח), reflection (רפלקציה) ו‑exploration (חקירה). התזה המרכזית: במיומנויות קוגניטיביות, ההבדל בין מתחיל למומחה איננו רק “יותר ידע תוכן”, אלא גם מערך של אסטרטגיות בקרה ושיפוט שמתרחשות לעיתים באופן סמוי—לכן ההוראה חייבת להפוך אותן לנראות כדי שהתלמיד יוכל לחקות, להתנסות ולבנות אותן. citeturn0search0turn0search4turn0search20  

במונחים של הדילמה A/B: החניכות הקוגניטיבית אינה רק “לעצב פעילויות”; היא מחייבת שלמישהו בסביבה יהיה תפקיד של “המומחה המדגים”. אם המורה אינו מתרגל בעצמו את הפרקטיקה (למשל: אימות טענות, בדיקת מקורות, ניהול ספק), קשה לו למלא את פונקציית ה‑modeling באופן עקבי ואמין. citeturn0search0turn4search19  

### למידה תצפיתית ומידול: למה “לראות איך עושים” משנה התנהגות, לא רק הבנה
תאוריות של למידה תצפיתית מצביעות על כך שתלמידים לומדים לא רק מהתוצאות ומההסברים, אלא גם מצפייה בביצוע—במיוחד כאשר הביצוע כולל רמזים של תשומת לב, בחירת אסטרטגיה, ותיקון טעויות. במילים אחרות: הדגמה אינה “קישוט”; היא מנגנון להעברת שליטה (control) וסכמות פעולה. citeturn2search30  
כאן, entity["people","אלברט בנדורה","social learning theorist"] רלוונטי במיוחד: אם תלמידים מפנימים נורמות ותהליכים דרך צפייה, אז גם בסביבת AI הם ילמדו “מה נחשב פעולה אינטלקטואלית” לפי מה שהמורה עושה בפועל—האם הוא בודק? האם הוא משווה מקורות? האם הוא מתקן ביטחון‑יתר? citeturn2search30turn2search17  

### מטא‑אנליזות על חשיבה ביקורתית והכוונה: הוראה מפורשת עובדת, אבל “טבילה בלבד” חלשה
מטא‑אנליזות גדולות על הוראת חשיבה ביקורתית מצביעות על אפקט ממוצע חיובי של התערבויות, אך גם על שונות גבוהה—כלומר, “זה עובד” תלוי באיך. יתרה מזו, מחקרים אלה מדגישים כי גישות שבהן התלמיד “אמור לפתח חשיבה ביקורתית” רק מתוך התנסות תוכן (“immersion”) נוטות להיות חלשות יותר מהוראה שמסבירה ומתרגלת במפורש אסטרטגיות של ניתוח, הערכה, והצדקה. citeturn0search5turn0search13  

המשמעות לדילמה A/B: אם מורה רק “מבין עקרונית” מהי הערכה ביקורתית ומכין פעילות, אך אינו יודע להדגים את תהליך הערכת‑הטענה בזמן אמת (למשל מול פלט AI שנשמע משכנע), הוא עלול להישאר ברמת “שפה על חשיבה” ולא “חשיבה בפועל”. זה מקשה במיוחד על העברה (transfer) למופעים חדשים, משום שהתלמיד לא בונה תסריט פעולה. citeturn0search5turn4search34  

### הכוונה בהוראה מבוססת חקירה: “פחות הנחיה” אינו בהכרח “יותר עצמאות”
מטא‑אנליזה מרכזית על הוראה מבוססת חקירה במדעים מצאה שלחקירה יש פוטנציאל השפעה חיובי, אך הדגישה שונות בהתאם למבנה הפעילות ולמידת ההכוונה. באופן כללי, “חקירה” שאינה נתמכת באבני דרך קוגניטיביות/אפיסטמיות ובתיווך עלולה להשאיר תלמידים עם פעילות מעניינת אך בלי בניית כלי חשיבה. citeturn4search0turn4search28  

בתרגום לסביבת GenAI: אם “לחקור בעזרת AI” הופך למשימה של ניסוי‑וטעייה ללא תיווך, התלמידים עלולים למקסם תוצר (טקסט/פתרון) במקום למקסם תהליך (בירור/בדיקה). לכן, גם בהוראה שמדגישה חקירה, המורה אינו “נעלם”; הוא מתווך ומדגים איך חקירה נראית. citeturn4search0turn1search1  

### העברה ומטא‑קוגניציה: למה המורה צריך להראות את “המעבר” ולא רק לקוות לו
העברה של מיומנויות חשיבה אינה מתרחשת באופן אוטומטי; ספרות על transfer מציעה אסטרטגיות כמו “hugging” (תקרוב ביצועים למצבי יעד) ו“bridging” (חיבורים מושגים בין הקשרים) יחד עם רפלקציה מטא‑קוגניטיבית כדי להגדיל את הסיכוי שהמיומנות תופיע במצבים חדשים. citeturn4search34turn4search18  
בהקשר זה, תרומתם של entity["people","דייוויד פרקינס","harvard education researcher"] ו‑entity["people","גבריאל סלומון","educational psychologist"] היא שהוראה ל‑transfer אינה “ללמד ואז לקוות”, אלא לעצב תנאים שמאכילים את המנגנון. בסביבה רוויית AI, התנאים הללו כוללים: היכולת לזהות מתי AI “עושה את העבודה”, מתי הוא טועה, ומתי צריך להעביר את השליטה חזרה לאדם—וזה בדיוק מה שהמורה צריך להדגים ולתרגל עצמו כדי להנכיח. citeturn4search34turn1search24  

## AI כמשבש אפיסטמי ומשנה לגיטימציה

### מה בדיוק “מתערער” כשהכיתה רוויה ב‑Generative AI
Generative AI משנה את הזרימה הבסיסית של “שאלה → מאמץ → תשובה → בדיקה” לזרימה חדשה: “שאלה/פרומפט → תשובה מידית → תחושת סגירה → (לעיתים) היעדר בדיקה”. מנגנון זה מסוכן במיוחד כי מודלי שפה יכולים להפיק טקסטים שוטפים ובטוחים‑לכאורה גם כשיש בהם טעויות—מה שמעלה את ערך היכולת האפיסטמית של **הצדקה ובקרה** (justification & control) על פני “שליפה של ידע”. citeturn1search1turn1search9turn1search24  

מחקר עדכני מציע ש‑GenAI מתפקד בכיתה כ”יודע חלופי”, ומבלי שמוסדות החינוך יתווכו זאת תמיד, הסמכות האפיסטמית זולגת מהמרחב האנושי‑חברתי אל המערכת האלגוריתמית. התוצאה האפשרית היא “צריכה אפיסטמית פסיבית”: תלמיד מקבל טענה ללא אימות וללא נימוק משלו. citeturn1search1turn2search9  

### תזוזת הסמכות: ממורה כמקור ידע למורה כמאמן סוכנות אפיסטמית
במצב כזה, תפקיד המורה נוטה להתמקם מחדש כמבוגר שאחראי על:
1) נורמות של “מה נחשב ידיעה” (criteria of knowing),  
2) פרקטיקות אימות והצלבה,  
3) חינוך לענווה אפיסטמית (“אני עשוי לטעות; נבדוק”),  
4) עיגון ערכי של החלטות—מתי מותר להשתמש ב‑AI, מתי לא, ומה האחריות על התוצר. citeturn1search1turn6search6turn6search13  

כאן מתהדקת הזיקה לדילמה A/B: אם המורה אינו מתרגל בעצמו את מהות התפקיד החדש (אימות, השוואת מקורות, ניהול דילמות), הוא יתקשה לעבור מ”מדריך פעילות” ל“מנטור אפיסטמי”. במקום זאת, הכיתה עלולה להפוך ל”מפעיל ChatGPT” עם שפה מוסרית כללית אך בלי פרקטיקה. citeturn1search1turn0search0turn1search4  

### אותנטיות ואמון: למה תלמידים מזהים פער בין אמירה להתנהגות
מחקר על תפיסות תלמידים לגבי אותנטיות מורה מציע שתלמידים בונים שיפוט אותנטיות לפי קריטריונים כמו מומחיות/כשירות, מחויבות, קוהרנטיות, ויחס. כאשר יש פער בין נורמות שהמורה מטיף להן לבין מה שהוא עושה בפועל—למשל איסור על תלמידים להשתמש ב‑AI לצד שימוש סמוי מצד המורה—התלמידים עשויים לפרש זאת כחוסר הוגנות או חוסר עקביות נורמטיבית, מה שפוגע בלגיטימציה של כללי המשחק. citeturn5search3turn6news50  

במקביל, מטא‑אנליזה רחבת טווח על “אמון מורים” (teacher trust) מצביעה על תרומה מתונה אך עקבית של אמון לתוצאות למידה, לצד השפעות של הנהגה בית‑ספרית על אמון. זה מחזק את הטענה שאמון אינו “רך” או שולי: במערכת שבה סמכות עוברת שינוי, אמון הוא תשתית שמכריעה אם תלמידים יאמצו נורמות חשיבה או יראו בהן הצגה. citeturn10search12turn2search4  

image_group{"layout":"carousel","aspect_ratio":"16:9","query":["teacher guiding students using AI in classroom","students verifying information online lateral reading tabs","Socratic seminar classroom discussion students questioning","teacher think aloud metacognition modeling classroom"],"num_per_query":1}

## ממצאים אמפיריים 2023–2026: AI, חשיבה ביקורתית, וצמצום מאמץ קוגניטיבי

### תמונת מצב מחקרית: מה חדש ומה עדיין חסר
הספרות על Generative AI וחינוך נעה במהירות, אך חשוב לציין שחלק משמעותי מהשיח עדיין מבוסס על מאמרי עמדה ומסגרות רעיוניות, ורק בשנים 2024–2026 יש עלייה במחקרים אמפיריים ממוקדי‑התנהגות. סקירות עדכניות מתארות את התחום כמסד נתונים שגדל, אך עדיין לא כתחום בוגר עם הרבה מחקרי התערבות מבוקרים על תוצרי חשיבה עמוקים. citeturn0search10turn3search4  

### offloading: כש‑AI הופך מפיגום קוגניטיבי לתחליף שיפוטי
שתי תצפיות אמפיריות מרכזיות עולות מהמחקר המתהווה:

1) מחקר סקר של entity["organization","Microsoft Research","microsoft research division"] על 319 עובדי ידע בדק מתי וכיצד אנשים “מבצעים חשיבה ביקורתית” בעת שימוש ב‑GenAI, ומדווח גם על קשר שלילי בין תדירות שימוש לבין מדדים של חשיבה ביקורתית, לצד מנגנונים מוצעים שכוללים ירידה בעיסוק בבדיקה כאשר המערכת נתפסת אמינה. למרות שמדובר במדגם שאינו תלמידים, הוא מספק אינדיקציה על הסיכון שמיומנויות שיפוט נשחקות כשיש שותף שמספק תשובות במהירות. citeturn0search19turn0search14  

2) מחקר נוסף מדווח שקשר בין שימוש בכלי AI לבין חשיבה ביקורתית מתווך באופן משמעותי על ידי offloading—האצלת משימות חשיבה לכלי. גם כאן, עיצוב המחקר בעיקר קורלטיבי ולכן הממצא אינו מוכיח ש‑AI “גורם” לירידה; ייתכן גם שאנשים עם נטייה חלשה לחשיבה ביקורתית נמשכים יותר לשימוש גבוה. אבל עצם התיווך מצביע על מנגנון פסיכולוגי סביר: כשמורידים באופן כרוני מאמץ מנטלי, מצטמצמת הזדמנות לתרגל ניטור והערכה. citeturn0search3turn1search24  

עבור הדילמה A/B, המשמעות היא חדה: אם תלמידים (ולעתים גם מורים) מחליקים באופן לא‑מודע לתוך offloading של שיפוט, אז לטפח “מערכת הפעלה אנושית” מחייב **תרבות כיתתית** שבה המבוגר המוביל מדגים באופן גלוי איך *לא* עושים offloading למקומות הלא‑נכונים (אימות, שיפוט ערכי, אחריות). בלי תרגול אישי של המורה, קשה לבנות פרקטיקה כזו כי המורה עצמו לא יזהה בזמן אמת את נקודת ההחלקה. citeturn1search1turn7search2  

### אימות והצלבה: אפשר ללמד “כוונות אימות” והתנהגות אימות—אבל זה דורש תיווך רציני
מחקר 2026 על “אינוקולציה” (inoculation training) בהקשר של שימוש ב‑ChatGPT בדק השפעה של הכשרה על כוונות אימות ועל אימות בפועל במשימות חינוכיות. ממצאיו, לפי התקציר, מצביעים על כך שהתערבות מכוונת יכולה להגביר נטייה לבצע אימות ולעבור מהסתמכות פסיבית לבקרה פעילה. זהו נתון חשוב: הוא מראה שהבעיה אינה “דטרמיניסטית”—אפשר לעצב התנהגות בדיקה. citeturn1search4  

אך העוקץ לדילמה A/B הוא שהכשרה כזו כמעט בהגדרה דורשת מישהו שמבין *במעשה* איך נראית בדיקה: מה בודקים ראשון, איך מחפשים “מקור נגדי”, איך מזהים ביטחון יתר של המערכת, ומה עושים כשאין מקור אמין. אם המורה לא תרגל בעצמו, הוא עלול להישאר בהנחיות כלליות (“תבדקו מקורות”) שמתקשות להתקיים מול הלחץ של עבודה מהירה. citeturn4search5turn1search4turn0search0  

### “הערכת מקורות” כמקרה בוחן: lateral reading והמשמעות שלו בעידן GPT
המחקר על lateral reading—כפי שתואר בעבודתו של entity["people","סם ויינברג","stanford historian"] ועמיתיו—מראה שמומחי בדיקת עובדות לא “קוראים לעומק באתר” אלא פותחים לשוניות, משווים, מחפשים הקשר, ומאמתים טענות מול מקורות חיצוניים. זהו בדיוק “פרוטוקול אנושי” שאמור להישאר מעל המכונה: לא לקבל טענה כי היא נשמעת טוב, אלא לייצר הצדקה. citeturn4search5turn4search17turn4search21  

בכיתה רוויה ב‑AI, lateral reading מקבל משמעות חדשה: הוא נהיה פרוטוקול נגד‑הזיה (anti‑hallucination) ונגד‑רטוריקת‑ביטחון. אבל כדי ללמד אותו, המורה מוכרח לדעת להפעיל אותו כהרגל—ולא רק “להזכיר” אותו. citeturn4search5turn1search1  

### יושרה אקדמית ואתיקה: לא רק “חוקים” אלא תרגול שיפוט במצבי גבול
מחקר אמפירי עשיר יותר ב‑2024–2025 מופיע סביב תפיסות של תלמידים לגבי “AI‑giarism” (שילוב AI ופלגיאט) ותפיסות מה נחשב שימוש פסול. מחקרים אלה מצביעים על בלבול נורמטיבי: סטודנטים משתמשים ב‑AI למגוון מטרות ולעיתים אינם בטוחים האם פעולה היא עזרה לגיטימית או עבירה. citeturn6search15turn6search6turn6search26  

במישור זה, “הבנה מושגית” של המורה אינה מספיקה אם הוא לא חי את דילמות הגבול: מהו “בעלות אינטלקטואלית” כשמשנים פרומפט שוב ושוב? מתי שימוש ליצירת מתווה הופך להחלפת כתיבה? מה מידת האחריות על הטיות? הספרות על יושרה בעידן AI מדגישה עקרונות כמו שקיפות, אחריותיות והוגנות—אך כדי להפוך עקרונות לפרקטיקה כיתתית, המורה חייב לתרגל הכרעות ודיונים אמיתיים. citeturn6search6turn6search19turn6search13  

## מקרים והתערבויות שבהם מורים תרגלו לפני שלימדו

### מורי‑מתכשרים שמתבקשים לעבוד עם ChatGPT ואז לעשות רפלקציה ביקורתית
מחקר איכותני (2024) בדק שימוש ב‑ChatGPT כעוזר תכנון שיעור אצל מתכשרים להוראת מתמטיקה: המתכשרים ניסו לפתור בעיה ולתכנן הוראה, ואז ביקשו מ‑ChatGPT לעשות זאת, ולאחר מכן ביצעו רפלקציה על הפלט. זהו מבנה שמכריח “התנסות → השוואה → ביקורת”, כלומר הוא מממש את עיקרון החניכות הקוגניטיבית אך בהיפוך מעניין: ה‑AI מספק “מודל” והמתכשר לומד לבקרו. citeturn3search5  

דפוס כזה חשוב לדילמה A/B כי הוא מציע שלפחות חלק מהמידול יכול להיות “מידול ביקורתי” של אינטראקציה עם AI—אבל הוא עדיין מחייב שהמורה/מנחה הקורס עצמו יודע להוביל את הרפלקציה, לזהות פערים פדגוגיים, ולהדגים כיצד הופכים פלט AI לעוגן לדיון על שיפוט אנושי. citeturn0search0turn1search1  

### שימוש ב‑GenAI ככלי לפיתוח מקצועי עצמי: כשהמורה מתרגל “למידה אדפטיבית” על עצמו
מחקר 2025 ב‑Springer מתאר שימוש של מורים ב‑ChatGPT כפלטפורמה לפיתוח מקצועי עצמי‑מכוון (self‑directed PD): כיצד הוא מסייע בפרקטיקות הוראה, וכיצד מורים תופסים את תפקידו. עצם הרעיון של SDPD דרך GenAI מדגים שהמורה אינו רק “משתמש לצרכים אדמיניסטרטיביים” אלא יכול להפוך את ה‑AI למראה שמפעילה רפלקציה מקצועית—וזה קריטי לכשירות הרביעית (“למידה אדפטיבית תחת אי‑ודאות”). citeturn3search8turn7search2  

עם זאת, אותו מנגנון יכול גם ליצור “אשליית שליטה” אם המורה מקבל בלי בדיקה המלצות לוגיסטיות/דידקטיות. לכן, PD שמבוסס GenAI מעלה את הצורך שמורים יתרגלו ביקורת על הכלי במסגרות בטוחות. citeturn3search4turn1search13  

### מורים מנהלים “משא ומתן על אמון” כלפי GenAI
מחקר איכותני 2025 מתאר כיצד מורים שוקלים אמון (trust negotiations) כשהם משלבים GenAI, כולל תהליך קולקטיבי של דיון וניסוי במסגרת סדנאות. תיאור כזה רלוונטי ישירות לטענה שהתגלמות אינה רק אינדיבידואלית: כדי לטפח נורמות של אימות ואחריות, מורים צריכים “אקולוגיה מקצועית” שבה הם מתנסים יחד, מנסחים כללים, ומפתחים שפה משותפת. citeturn1search13  

### הכשרה ייעודית להעלאת מיומנות מורים ב‑ChatGPT: דוגמה להתגלמות כמסלול הפיכתי
מחקר מקרה 2025 על קורס הכשרה למורים סביב ChatGPT מציג מודל של upskilling: עיצוב והעברה של הכשרה, ובחינה כיצד היא עונה על צורך שצמח מהר. גם אם מחקרי מקרה אינם הוכחה כללית, הם מראים שהמערכת מתחילה להתייחס לשימוש ב‑GenAI כפרקטיקה שמורים צריכים לתרגל במכוון לפני שיבקשו מתלמידים לעשות זאת בצורה אחראית. citeturn3search12turn3search28  

### הערת איכות‑ראיות
מקרי ההתערבות הללו מחזקים בעיקר מנגנון plausibility: הם מראים כיצד “תרגול לפני הוראה” מתרחש בפועל. אך הם עדיין לא מספקים, ברובם, ניסויים השוואתיים ישירים בין מורים שתרגלו לעומק לבין מורים שמבינים מושגית בלבד. לכן, כאן ההיסק הוא “היסק מבוסס מנגנון” יותר מאשר “הוכחה סיבתית חותכת”. citeturn3search4turn0search10  

## טיעוני נגד וגבולות: מתי הנחיה יכולה לעבוד בלי התגלמות מלאה

### טיעון הנגד החזק: “המורה יכול להיות מתווך של פרוטוקולים” בלי להיות “מתרגל עמוק”
אפשר לטעון שבחלק מהכשירויות, אין צורך שהמורה יעסוק בעצמו באותה תדירות או עומק כמו תלמידים. הוא יכול:
* להשתמש במערכי שיעור מובנים, דוגמאות מתועדות (כולל וידאו‑מודלים), ופרוטוקולי בדיקה מוכנים. citeturn4search19turn4search5  
* לאפשר לתלמידים ליצור ידע דרך חקירה, כאשר המורה מתמקד ב‑scaffolding ולא ב‑performing. ספרות על חקירה תומכת בהכוונה מבנית, שאינה בהכרח “מופע מומחיות” מלא בכל רגע. citeturn4search0turn4search28  
* להישען על מודלים חיצוניים של מומחיות (למשל דוגמאות של fact‑checkers) כדי ללמד הערכת מקורות, גם אם המורה עצמו פחות משתמש בזה ביום‑יום. citeturn4search17turn4search21  

טיעון זה חשוב מוסרית ומערכתית: אם נדרוש “התמרה פנימית מלאה” כתנאי ללגיטימציה מקצועית, עלולות להיווצר חסימות, בושה מקצועית, ואי‑שוויון בין מורים לפי זמן/משאבים/גישה לכלים. citeturn3search4turn10search12  

### גבול שני: סכנת “משחק תפקידים” והטיית‑יתר לטובת AI
גם התגלמות יכולה להיות מסוכנת אם היא לא רפלקטיבית: מורה שמתרגל GenAI אך מתאהב ביעילות עלול להפוך את הכיתה למערכת offloading שיטתית. כלומר, לא כל “פרקטיקה” היא “כשירות אנושית”; צריך להבחין בין אימון בשימוש לבין אימון בשיפוט‑על‑השימוש. citeturn0search3turn1search24turn1search1  

### תיאור גבולות סבירים: “התגלמות מינימלית מספיקה” לעיתים, אך רק אם המורה שומר על שלושה תנאים
הספרות מצביעה (באופן עקיף) על שלושה תנאים שבאמצעותם ניתן להפחית את הצורך בהתגלמות מלאה ועדיין ללמד הרבה:
1) **הוראה מפורשת של אסטרטגיות** (ולא “טבילה” בלבד), כפי שמוצע במחקר על חשיבה ביקורתית. citeturn0search5turn0search13  
2) **הערכה אותנטית שמחייבת תהליך** (ולא רק תוצר), בהתאם לספרות על “אותנטיות” בלמידה ובפרקטיקות הערכה. citeturn5search32turn5search20  
3) **שקיפות נורמטיבית ועקביות התנהגותית**, משום שתלמידים בונים תפיסת אותנטיות ואמון מפרקטיקות עקביות. citeturn5search3turn10search12  

בהיעדר שלושת התנאים, “הנחיה בלי התגלמות” נוטה להפוך לרטוריקה: התלמידים שומעים עקרונות אבל לא מקבלים הרגלים. citeturn2search5turn0search0  

## סינתזה: תנאים הכרחיים, השלכות לפיתוח מקצועי ומדיניות, ומגבלות

### תשובה מסכמת לדילמה A/B
המחקר אינו מספק “פסק דין ניסויי” ישיר על A מול B עבור כל חמש הכשירויות, אך הוא מספק בסיס חזק להיסק הבא:

**כדי לטפח את חמש כשירויות “מערכת ההפעלה האנושית” באופן עקבי ועמיד בסביבה רוויה ב‑AI, מורים צריכים יותר מהבנה מושגית ותכנון פעילויות. הם צריכים רמה מהותית של התגלמות: תרגול אישי, חשיפה לקשיים, ומידול של תהליכי בקרה ושיפוט.** citeturn0search0turn0search5turn1search1turn7search2  

עם זאת, “התגלמות” אינה חייבת להיות קיצונית: יש הצדקה חזקה למודל של **התגלמות מספיקה** (sufficient embodiment)—כלומר, לפחות מספיק תרגול כדי:
(א) לזהות פיתויי offloading,  
(ב) להדגים אימות והצלבה,  
(ג) להוביל דיון ערכי על שימוש,  
(ד) לבצע רפלקציה מקצועית מתמשכת. citeturn0search3turn1search4turn6search6turn1search7  

### תנאים מעשיים לטיפוח כל חמש הכשירויות תוך “התגלמות מספיקה”
להלן ניסוח של “תנאי מינימום” (לא צ’ק‑ליסט טכני, אלא תנאי אפיסטמי‑מוסרי) לכל כשירות:

**ניסוח שאלות / משמעת חקירה**  
מורה צריך להראות כיצד שאלה מתפתחת מחוסר‑בהירות להיפותזה ולבדיקה: ניסוח מחדש, חידוד קריטריונים (“מה יחשב תשובה טובה?”), והפיכת שאלות לשרשרת אימות. ניסיון ממחקר על חקירה ולמידה פעילה מציע שהכוונה אפיסטמית היא חלק קריטי—ולכן המורה צריך לתרגל חקירה בעצמו כדי לתווך אותה. citeturn4search0turn8search0turn0search0  

**הערכה ביקורתית של פלט AI**  
המרכיב שאינו ניתן להחלפה הוא פיתוח “פרוטוקולי חשדנות”: lateral reading, טריאנגולציה, ובדיקת טענות/ציטוטים. מחקר על אימון אימות מציע שאפשר לשנות כוונות והתנהגות, אך רק כשמאמנים פרקטיקות קונקרטיות. מורה שלא חווה בעצמו “טעות משכנעת” של AI יתקשה להדגים את נקודת ההיזקקות לבדיקה. citeturn1search4turn4search5turn1search1  

**שיפוט אתי ושימוש אחראי**  
כאן התגלמות קרובה במיוחד להכרח: ספרות על חינוך מוסרי/אופי מצביעה על אפקטים חיוביים מתונים של תוכניות, אבל מדגישה עקביות, אקלים, והיות מבוגרים משמעותיים חלק מההקשר. בעידן AI, שבו “AI‑giarism” מערער קטגוריות, תלמידים צריכים לראות מבוגר שמכריע במצבי גבול, מסביר את הנימוק הערכי, ומיישם את אותם כללים על עצמו (שקיפות). citeturn5search0turn6search15turn6search13turn10search12  
במסגרת פסיכולוגית של רכיבי פעולה מוסרית, ניתן לחשוב על התחום דרך ארבעה רכיבים של רגישות‑שיפוט‑מוטיבציה‑פעולה אצל entity["people","ג'יימס רסט","moral psychologist"] והרחבות אצל entity["people","דרסיה נרבייז","moral development scholar"]: “ללמד אתיקה” דורש יותר מהגדרות; הוא דורש תרגול רכיבי פעולה במצבים אמיתיים. citeturn6search14turn6search11turn6search18  

**למידה אדפטיבית תחת אי‑ודאות טכנולוגית**  
מטא‑אנליזות על SRL ומטא‑קוגניציה מצביעות על כך שהתערבויות יכולות לשפר אסטרטגיות, הישגים ומוטיבציה. אך SRL נלמד טוב יותר כשהמורה מדגים ניטור, תכנון, והערכת איכות—לא רק מבקש מהתלמיד “להיות רפלקטיבי”. כאן ההתגלמות היא שהמורה עצמו מראה איך הוא מעדכן את הידע שלו, מודה באי‑ודאות, ובוחר אסטרטגיות בדיקה. citeturn1search7turn1search15turn7search2turn4search19  

**שמירת האדם מעל המכונה**  
זהו צומת של שיפוט, אחריות, ויחסים. מטא‑אנליזות על SEL מצביעות על שיפור בתחומים רגשיים‑חברתיים וגם הישגים; ומטא‑אנליזה על אמון מורים מצביעה על קשר עקבי לתוצאות. מכאן שהמורה אינו יכול “להאציל” את הליבה הזו ל‑AI: הוא חייב לגלם אותה—באופן שבו הוא מתייחס לתלמידים, באופן שבו הוא מייצר מקום לטעות אנושית, ובאופן שבו הוא מגדיר גבולות שימוש. citeturn2search3turn5search26turn10search12  

### השלכות לפיתוח מקצועי: “פיתוח כשירות” כמעבדה של פרקטיקה ולא כסדנת מושגים
אם מקבלים את הטענה ש‑B‑lite נדרש, אז פיתוח מקצועי אפקטיבי אינו צריך להיראות כ”השתלמות כלי AI” אלא כ”פרקטיקום אפיסטמי‑מוסרי” בסגנון reflective practicum:
1) תרגול שימוש ב‑AI בתוך משימות הוראה אמיתיות (תכנון, בניית שאלות, יצירת משוב),  
2) ביצוע audits שיטתיים: היכן ה‑AI טעה? היכן הוא הטה? היכן הוא גרם ל‑offloading?  
3) בניית פרוטוקולים כיתתיים לאימות ושקיפות,  
4) רפלקציה קבוצתית על אמון—כפי שמראים מחקרים על משא ומתן של אמון בקרב מורים. citeturn1search13turn3search8turn3search4turn7search2  

סקירה שיטתית על AI בהוראה ובהתפתחות מקצועית מצביעה על כך שתחום ה‑PD סביב AI עדיין מתפתח ושיש פערים בין “היצע” הכשרות לבין “ביקוש” ופרקטיקות בשדה. זה מחזק שהמערכת צריכה לעצב PD כתרגול מתמשך ולא כאירוע חד‑פעמי. citeturn3search4  

### השלכות למדיניות והערכת‑למידה: להפוך “תהליך” לנראה ומוערך
למרות שהדוח אינו מסמך מדיניות, יש מסקנה ישירה: אם רוצים לטפח כשירויות מערכת‑הפעלה, הערכה צריכה לתגמל תהליך, לא רק תוצר—כדי למנוע מעבר מלא של העבודה ל‑AI. ספרות על הערכה/למידה אותנטית מדגישה התאמה בין משימות להקשרים אמיתיים; בעידן AI, “אמיתי” פירושו גם היכולת להסביר החלטות, להציג בדיקות, ולהצהיר שימוש. citeturn5search20turn5search32turn6search13  

### מגבלות ושאלות פתוחות
הפער המחקרי המרכזי הוא **מחסור במחקרים ישירים** שמודדים: האם תלמידים מפתחים טוב יותר את חמש הכשירויות כאשר המורים עצמם מתרגלים אותן באופן אותנטי, לעומת מורים שמלמדים אותן דרך מערכי שיעור “מעל הראש”. רוב הראיות כיום הן:
* ראיות תיאורטיות‑מנגנוניות (חניכות קוגניטיבית, מידול, SRL, transfer). citeturn0search0turn4search34turn1search7  
* ראיות אמפיריות‑מתהוות על השפעות GenAI על חשיבה/אימות/יושרה, שרבות מהן קורלטיביות. citeturn0search19turn0search3turn6search15  

שאלות מחקר פתוחות בעלות ערך גבוה כוללות:  
(א) אילו רכיבים מכל אחת מחמש הכשירויות הם “הכי מגולמים” ולכן מחייבים מידול חי? citeturn0search0turn7search2  
(ב) מהו “סף התגלמות” מינימלי שמספיק כדי לשמור על לגיטימציה ואמון? citeturn5search3turn10search12  
(ג) כיצד מודדים בפועל “שמירת האדם מעל המכונה” בלי להיסחף למדדים התנהגותיים שטחיים? citeturn5search0turn5search26  
(ד) האם אימון אימות (כמו inoculation training) עובד אחרת כשמורה עצמו מדגים “כשלון ותיקון” מול AI? citeturn1search4turn1search1